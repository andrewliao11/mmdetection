{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = [\"cityscapes_train\", \"sim10k\"]\n",
    "test_datasets = [\"cityscapes\", \"sim200k\"]\n",
    "ngc_id = 2838351"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = []\n",
    "train_labels = []\n",
    "for i, dset in enumerate(train_datasets):\n",
    "    p = list(glob(f\"/home/andliao/results/extract_features/*/{ngc_id}_{dset}.pkl\"))\n",
    "    assert len(p) == 1\n",
    "    p = p[0]\n",
    "\n",
    "    outs = pkl.load(open(p, \"rb\"))\n",
    "    for out in outs:\n",
    "        feat = out[-1]\n",
    "        train_features.append(feat[0].mean(-1).mean(-1))     # average pooling\n",
    "        train_labels.append(i)\n",
    "\n",
    "\n",
    "train_features = np.array(train_features)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = []\n",
    "test_labels = []\n",
    "for i, dset in enumerate(test_datasets):\n",
    "    p = list(glob(f\"/home/andliao/results/extract_features/*/{ngc_id}_{dset}.pkl\"))\n",
    "    assert len(p) == 1\n",
    "    p = p[0]\n",
    "\n",
    "    outs = pkl.load(open(p, \"rb\"))\n",
    "    for out in outs:\n",
    "        feat = out[-1]\n",
    "        test_features.append(feat[0].mean(-1).mean(-1))     # average pooling\n",
    "        test_labels.append(i)\n",
    "\n",
    "test_features = np.array(test_features)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('sgdclassifier', SGDClassifier())])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7824113475177304"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = np.mean(clf.predict(test_features) == test_labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1fbd81b1948db4ad2c9759b314da344b172db15f8026cdb0f8ec083c593f3fc"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('label-translation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
